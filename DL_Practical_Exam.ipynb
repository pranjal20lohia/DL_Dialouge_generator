{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Without Attention**"
      ],
      "metadata": {
        "id": "7KLfN79lan6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 2: Load the uploaded CSV files into pandas DataFrames\n",
        "train_df = pd.read_csv('train.csv')\n",
        "valid_df = pd.read_csv('validation.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Step 3: Preview the data\n",
        "print(\"Train Sample:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nValidation Sample:\")\n",
        "print(valid_df.head())\n",
        "\n",
        "print(\"\\nTest Sample:\")\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWDRz9obKVe3",
        "outputId": "1edfd4fe-24d5-4426-a050-b873213b5594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Sample:\n",
            "                                              dialog                    act  \\\n",
            "0  ['Say , Jim , how about going for a few beers ...  [3 4 2 2 2 3 4 1 3 4]   \n",
            "1  ['Can you do push-ups ? '\\n \" Of course I can ...          [2 1 2 2 1 1]   \n",
            "2  ['Can you study with the radio on ? '\\n ' No ,...            [2 1 2 1 1]   \n",
            "3  ['Are you all right ? '\\n ' I will be all righ...              [2 1 1 1]   \n",
            "4  ['Hey John , nice skates . Are they new ? '\\n ...    [2 1 2 1 1 2 1 3 4]   \n",
            "\n",
            "                 emotion  \n",
            "0  [0 0 0 0 0 0 4 4 4 4]  \n",
            "1          [0 0 6 0 0 0]  \n",
            "2            [0 0 0 0 0]  \n",
            "3              [0 0 0 0]  \n",
            "4    [0 0 0 0 0 6 0 6 0]  \n",
            "\n",
            "Validation Sample:\n",
            "                                              dialog  \\\n",
            "0  ['Good morning , sir . Is there a bank near he...   \n",
            "1  ['Good afternoon . This is Michelle Li speakin...   \n",
            "2  ['What qualifications should a reporter have ?...   \n",
            "3  ['Hi , good morning , Miss ? what can I help y...   \n",
            "4  [\"Excuse me , ma'am . Can you tell me where th...   \n",
            "\n",
            "                                 act                            emotion  \n",
            "0                    [2 1 3 2 1 2 1]                    [0 0 0 0 0 0 0]  \n",
            "1              [2 1 1 1 1 2 3 2 3 4]              [0 0 0 0 0 0 0 0 0 0]  \n",
            "2                          [2 1 2 1]                          [0 0 0 0]  \n",
            "3  [2 3 2 2 1 2 1 2 1 1 1 3 2 1 3 4]  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4]  \n",
            "4                  [3 4 2 1 2 1 1 1]                  [0 0 0 0 0 0 4 4]  \n",
            "\n",
            "Test Sample:\n",
            "                                              dialog  \\\n",
            "0  ['Hey man , you wanna buy some weed ? ' ' Some...   \n",
            "1  ['The taxi drivers are on strike again . ' ' W...   \n",
            "2  [\"We've managed to reduce our energy consumpti...   \n",
            "3  ['Believe it or not , tea is the most popular ...   \n",
            "4  ['What are your personal weaknesses ? '\\n ' I ...   \n",
            "\n",
            "                             act                        emotion  \n",
            "0      [3 2 3 4 3 4 3 2 3 4 2 3]      [0 6 0 0 0 0 0 0 0 0 3 0]  \n",
            "1                      [1 2 1 1]                      [0 0 0 0]  \n",
            "2                [1 2 1 2 1 2 1]                [0 0 0 0 0 0 0]  \n",
            "3  [1 1 1 1 2 2 2 2 1 1 1 3 4 3]  [0 0 0 0 0 0 0 0 0 4 0 0 4 4]  \n",
            "4              [2 1 2 1 2 1 2 1]              [0 0 0 0 0 0 0 4]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning and Tokenization**"
      ],
      "metadata": {
        "id": "MncYF5ngZT6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # For tokenizing text\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # For padding sequences\n",
        "import numpy as np  # For numerical operations\n",
        "import re  # For regex-based text cleaning\n",
        "\n",
        "# Extract non-null dialogues from the DataFrame\n",
        "dialogues = train_df[\"dialog\"].dropna().tolist()\n",
        "\n",
        "# Lists to store input (previous utterance) and target (next utterance) text pairs\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "# Debugging: Print the first few raw dialogues to inspect their format\n",
        "print(\"First few raw dialogues:\")\n",
        "print(dialogues[:3])\n",
        "\n",
        "# Iterate over each dialogue to preprocess and extract input-output pairs\n",
        "for dialogue in dialogues:\n",
        "    # Step 1: Remove brackets and quotes around the whole string (e.g., \"['Hello']\" => \"Hello\")\n",
        "    dialogue_clean = re.sub(r'^\\[[\\'\"](.*)[\\'\"]\\]$', r'\\1', dialogue.strip())\n",
        "\n",
        "    # Step 2: Replace escaped quotes and newline characters with standard versions\n",
        "    dialogue_clean = dialogue_clean.replace('\\\\\\'', \"'\").replace('\\\\\"', '\"').replace('\\n', ' ')\n",
        "\n",
        "    # Step 3: Split dialogue into individual utterances\n",
        "    if \"__eou__\" in dialogue_clean:\n",
        "        # If '__eou__' is used as a delimiter, split on it\n",
        "        utterances = [u.strip() for u in dialogue_clean.split(\"__eou__\") if u.strip()]\n",
        "    else:\n",
        "        # Otherwise, use regex to extract phrases enclosed in quotes\n",
        "        utterances = re.findall(r'[\\'\"](.*?)[\\'\"]', dialogue_clean)\n",
        "        utterances = [u.strip() for u in utterances if u.strip()]\n",
        "\n",
        "    # Step 4: Form input-output sentence pairs from consecutive utterances\n",
        "    if len(utterances) > 1:\n",
        "        for i in range(len(utterances) - 1):\n",
        "            input_texts.append(utterances[i])         # Current utterance as input\n",
        "            target_texts.append(utterances[i + 1])    # Next utterance as output\n",
        "\n",
        "# Debugging: Check how many pairs were formed and preview some\n",
        "print(f\"\\nNumber of input-output pairs: {len(input_texts)}\")\n",
        "if input_texts:\n",
        "    print(\"First 3 input-output pairs:\")\n",
        "    for i in range(min(3, len(input_texts))):\n",
        "        print(f\"Input: {input_texts[i]}\")\n",
        "        print(f\"Target: {target_texts[i]}\\n\")\n",
        "else:\n",
        "    # Raise error if no usable data was generated\n",
        "    raise ValueError(\"No input-output pairs were created. Check dialogue formatting.\")\n",
        "\n",
        "# Initialize tokenizer and set OOV (out-of-vocabulary) token\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "\n",
        "# Fit tokenizer on all texts (input and target) to build vocabulary\n",
        "tokenizer.fit_on_texts(input_texts + target_texts)\n",
        "\n",
        "# Convert texts to sequences of integers\n",
        "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
        "target_sequences = tokenizer.texts_to_sequences(target_texts)\n",
        "\n",
        "# Find maximum length of input and target sequences for padding\n",
        "max_input_len = max(len(seq) for seq in input_sequences) if input_sequences else 0\n",
        "max_target_len = max(len(seq) for seq in target_sequences) if target_sequences else 0\n",
        "\n",
        "# Pad input sequences to have uniform length\n",
        "encoder_input_data = pad_sequences(input_sequences, maxlen=max_input_len, padding='post')\n",
        "\n",
        "# Pad target sequences similarly\n",
        "decoder_input_data = pad_sequences(target_sequences, maxlen=max_target_len, padding='post')\n",
        "\n",
        "# Prepare decoder target data by shifting decoder input one step left\n",
        "decoder_target_data = np.zeros_like(decoder_input_data)              # Initialize with zeros\n",
        "decoder_target_data[:, :-1] = decoder_input_data[:, 1:]              # Shift all tokens left\n",
        "decoder_target_data[:, -1] = 0                                       # Last token is padding\n",
        "\n",
        "# Final debugging: print shapes of processed input and output arrays\n",
        "print(\"\\nEncoder input shape:\", encoder_input_data.shape)\n",
        "print(\"Decoder input shape:\", decoder_input_data.shape)\n",
        "print(\"Decoder target shape:\", decoder_target_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPE_soYQ9zRa",
        "outputId": "a046ce05-f037-43d8-daaa-600a8bd21c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few raw dialogues:\n",
            "['[\\'Say , Jim , how about going for a few beers after dinner ? \\'\\n \\' You know that is tempting but is really not good for our fitness . \\'\\n \\' What do you mean ? It will help us to relax . \\'\\n \" Do you really think so ? I don\\'t . It will just make us fat and act silly . Remember last time ? \"\\n \" I guess you are right.But what shall we do ? I don\\'t feel like sitting at home . \"\\n \\' I suggest a walk over to the gym where we can play singsong and meet some of our friends . \\'\\n \" That\\'s a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them . \"\\n \\' Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too . \\'\\n \" Good.Let \\' s go now . \" \\' All right . \\']', '[\\'Can you do push-ups ? \\'\\n \" Of course I can . It\\'s a piece of cake ! Believe it or not , I can do 30 push-ups a minute . \"\\n \" Really ? I think that\\'s impossible ! \" \\' You mean 30 push-ups ? \\'\\n \\' Yeah ! \\'\\n \" It\\'s easy . If you do exercise everyday , you can make it , too . \"]', '[\\'Can you study with the radio on ? \\'\\n \\' No , I listen to background music . \\' \\' What is the difference ? \\'\\n \\' The radio has too many comerials . \\'\\n \" That\\'s true , but then you have to buy a record player . \"]']\n",
            "\n",
            "Number of input-output pairs: 64618\n",
            "First 3 input-output pairs:\n",
            "Input: Say , Jim , how about going for a few beers after dinner ?\n",
            "Target: You know that is tempting but is really not good for our fitness .\n",
            "\n",
            "Input: You know that is tempting but is really not good for our fitness .\n",
            "Target: What do you mean ? It will help us to relax .\n",
            "\n",
            "Input: What do you mean ? It will help us to relax .\n",
            "Target: Do you really think so ? I don\n",
            "\n",
            "\n",
            "Encoder input shape: (64618, 235)\n",
            "Decoder input shape: (64618, 235)\n",
            "Decoder target shape: (64618, 235)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM-based Encoder-Decoder Architecture (without Attention)**"
      ],
      "metadata": {
        "id": "cNUNADm_T-6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary Keras modules for building the model\n",
        "from tensorflow.keras.models import Model              # For defining a multi-input/output model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding  # Layers used in the Seq2Seq architecture\n",
        "from tensorflow.keras.optimizers import Adam           # Optimizer\n",
        "import time                                             # Optional: can be used to track training time\n",
        "\n",
        "# -------------------------------\n",
        "# Hyperparameters for the model\n",
        "# -------------------------------\n",
        "vocab_size = len(tokenizer.word_index) + 1              # Total number of unique words + 1 for padding/OOV\n",
        "embedding_dim = 256                                     # Dimension of word embeddings (each word → 256-d vector)\n",
        "lstm_units = 512                                        # Number of units in the LSTM layer (affects model capacity)\n",
        "batch_size = 64                                         # Number of samples per training batch\n",
        "epochs = 10                                             # Total number of passes through the entire dataset during training\n",
        "\n",
        "# -------------------------------\n",
        "# Encoder Network\n",
        "# -------------------------------\n",
        "encoder_inputs = Input(shape=(None,))                   # Input placeholder for encoder (None → variable sequence length)\n",
        "enc_emb = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
        "# Embedding layer:\n",
        "#   - vocab_size: total vocabulary size\n",
        "#   - embedding_dim: dimensionality of embeddings\n",
        "#   - mask_zero=True: ignores padding (0) in LSTM processing\n",
        "\n",
        "encoder_lstm = LSTM(lstm_units, return_state=True)      # LSTM that returns hidden and cell state\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# encoder_outputs: last output of the encoder (not used here)\n",
        "# state_h: final hidden state of the encoder LSTM\n",
        "# state_c: final cell state of the encoder LSTM\n",
        "\n",
        "encoder_states = [state_h, state_c]                     # Encoder states to be passed to the decoder as initial state\n",
        "\n",
        "# -------------------------------\n",
        "# Decoder Network\n",
        "# -------------------------------\n",
        "decoder_inputs = Input(shape=(None,))                   # Input placeholder for decoder (sequence of target tokens)\n",
        "dec_emb = Embedding(vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n",
        "# Same embedding layer for decoder input as in encoder\n",
        "\n",
        "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
        "# LSTM:\n",
        "#   - return_sequences=True: output at each time step (needed for sequence-to-sequence)\n",
        "#   - return_state=True: return final hidden and cell state (for inference or stacking)\n",
        "\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "# Decoder LSTM initialized with encoder's final states to maintain context\n",
        "\n",
        "decoder_dense = Dense(vocab_size, activation='softmax') # Fully connected layer to predict next word from decoder LSTM output\n",
        "decoder_outputs = decoder_dense(decoder_outputs)        # Apply dense layer to each output timestep\n",
        "\n",
        "# -------------------------------\n",
        "# Define and compile the full model\n",
        "# -------------------------------\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "# Inputs: encoder input sequence and decoder input sequence\n",
        "# Output: decoder output predictions (token probabilities at each timestep)\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy')\n",
        "# Adam: adaptive learning rate optimizer (0.001 is the learning rate)\n",
        "# sparse_categorical_crossentropy: used because target sequences are integers, not one-hot encoded\n",
        "\n",
        "# Print model architecture summary\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "sj9JE_FaTwce",
        "outputId": "05cc5cfe-6db5-49af-dea6-24b7e3452d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,859,712\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,859,712\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),     │  \u001b[38;5;34m1,574,912\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m1,574,912\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m7,734,501\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│                     │ \u001b[38;5;34m15077\u001b[0m)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,859,712</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,859,712</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,734,501</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15077</span>)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,603,749\u001b[0m (70.97 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,603,749</span> (70.97 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,603,749\u001b[0m (70.97 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,603,749</span> (70.97 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the Model**"
      ],
      "metadata": {
        "id": "UWPaxBQV4O8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train/test sets (e.g., 80% train, 20% test)\n",
        "encoder_input_train, encoder_input_test, decoder_input_train, decoder_input_test, decoder_target_train, decoder_target_test = train_test_split(\n",
        "    encoder_input_data, decoder_input_data, decoder_target_data, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "dcegIgwMc3Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# Take only a small fraction (1%) of the data\n",
        "# ---------------------------------------------\n",
        "sample_size = len(encoder_input_data) // 100\n",
        "# sample_size: calculates 1% of the total dataset size using integer division (//)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Create a smaller training subset for quick testing/debugging\n",
        "# ---------------------------------------------\n",
        "small_encoder = encoder_input_data[:sample_size]       # First 1% of encoder input sequences\n",
        "small_decoder = decoder_input_data[:sample_size]       # First 1% of decoder input sequences\n",
        "\n",
        "# Prepare corresponding decoder target data\n",
        "small_target = np.zeros_like(small_decoder)            # Create an array of zeros with the same shape as decoder input\n",
        "small_target[:, :-1] = small_decoder[:, 1:]            # Shift decoder input left by 1 to form the target (next-token prediction)\n",
        "# Example:\n",
        "# decoder_input:   [<start> How are you]\n",
        "# decoder_target:  [How are you <end>]\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Train the model on the small subset\n",
        "# ---------------------------------------------\n",
        "start_time = time.time()                               # Record training start time to measure duration\n",
        "\n",
        "history = model.fit(\n",
        "    [small_encoder, small_decoder],                    # Input data: encoder and decoder inputs\n",
        "    small_target,                                      # Target output: decoder next-token sequences\n",
        "    batch_size=32,                                     # Batch size: number of samples processed before model updates (smaller = faster)\n",
        "    epochs=epochs,                                     # Number of passes through the entire dataset (defined earlier as 10)\n",
        "    validation_split=0.2,                              # 20% of this small data will be used as validation set\n",
        "    verbose=1                                          # Verbose=1: shows progress bar and detailed output during training\n",
        ")\n",
        "\n",
        "print(f\"Fast training completed in {time.time()-start_time:.2f} seconds\")\n",
        "# Print total time taken for training this small subset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaqdHt0BeMMB",
        "outputId": "2188ecfc-23d0-466b-d174-d24eaaf6ab43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 9.2602 - val_loss: 6.8116\n",
            "Epoch 2/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 192ms/step - loss: 6.2810 - val_loss: 7.1574\n",
            "Epoch 3/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 5.9215 - val_loss: 7.0207\n",
            "Epoch 4/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 5.6827 - val_loss: 7.0085\n",
            "Epoch 5/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 193ms/step - loss: 5.6907 - val_loss: 6.9702\n",
            "Epoch 6/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 5.6276 - val_loss: 6.9517\n",
            "Epoch 7/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - loss: 5.6098 - val_loss: 6.9531\n",
            "Epoch 8/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 194ms/step - loss: 5.6330 - val_loss: 6.9059\n",
            "Epoch 9/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 193ms/step - loss: 5.7289 - val_loss: 6.8910\n",
            "Epoch 10/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 214ms/step - loss: 5.6700 - val_loss: 6.7459\n",
            "Fast training completed in 48.19 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metrics**"
      ],
      "metadata": {
        "id": "mVCUtzORa_5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import os\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "valid_df = pd.read_csv(\"validation.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Drop missing values\n",
        "train_df = train_df.dropna()\n",
        "\n",
        "# Extract input and target texts\n",
        "input_texts = train_df['dialog'].astype(str).tolist()  # Input sequences (dialogues)\n",
        "target_texts = train_df['act'].astype(str).apply(lambda x: '<start> ' + x + ' <end>').tolist()  # Target sequences (actions)\n",
        "\n",
        "# Tokenize the input and target texts\n",
        "tokenizer = Tokenizer(filters='', oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(input_texts + target_texts)  # Fit tokenizer on both input and target texts\n",
        "\n",
        "# Convert texts to sequences\n",
        "input_seq = tokenizer.texts_to_sequences(input_texts)\n",
        "target_seq = tokenizer.texts_to_sequences(target_texts)\n",
        "\n",
        "# Find the maximum sequence lengths for input and target sequences\n",
        "max_input_len = max(len(seq) for seq in input_seq)\n",
        "max_target_len = max(len(seq) for seq in target_seq)\n",
        "\n",
        "# Padding sequences to a fixed length\n",
        "input_seq = pad_sequences(input_seq, maxlen=max_input_len, padding='post')\n",
        "target_seq = pad_sequences(target_seq, maxlen=max_target_len, padding='post')\n",
        "\n",
        "# Split the target sequence into decoder input and decoder output\n",
        "decoder_input = target_seq[:, :-1]  # The decoder input is the target sequence excluding the last token\n",
        "decoder_output = target_seq[:, 1:]  # The decoder output is the target sequence excluding the first token\n",
        "\n"
      ],
      "metadata": {
        "id": "7RceyU4yht3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, GRU, AdditiveAttention, Concatenate, Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define fixed sizes\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 256\n",
        "latent_dim = 256\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_input_len,))\n",
        "enc_emb = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
        "enc_outputs, enc_state = GRU(latent_dim, return_sequences=True, return_state=True)(enc_emb)\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(max_target_len - 1,))\n",
        "dec_emb = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
        "dec_outputs, _ = GRU(latent_dim, return_sequences=True, return_state=True)(dec_emb, initial_state=enc_state)\n",
        "\n",
        "# Attention\n",
        "attention = AdditiveAttention()\n",
        "context_vector = attention([dec_outputs, enc_outputs])\n",
        "\n",
        "# Concatenate context with decoder output\n",
        "concat = Concatenate(axis=-1)([context_vector, dec_outputs])\n",
        "\n",
        "# Final dense layer\n",
        "final_output = Dense(vocab_size, activation='softmax')(concat)\n",
        "\n",
        "# Compile model\n",
        "attn_model = Model([encoder_inputs, decoder_inputs], final_output)\n",
        "attn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "SaFTLTMmkNw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np  # Import NumPy (not directly used in this code, but good for future extensions)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Sample model output predictions and reference texts\n",
        "# -------------------------------------------------\n",
        "predictions = [\"the cat sat on the mat\", \"this is a test sentence\"]  # Model-generated sentences\n",
        "references = [\"the cat is sitting on the mat\", \"this is a test\"]      # Ground truth/reference sentences\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Function to tokenize text into individual words (tokens)\n",
        "# -------------------------------------------------\n",
        "def tokenize(text):\n",
        "    return text.split()  # Split string by spaces to create a list of words\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Function to calculate token-level accuracy\n",
        "# -------------------------------------------------\n",
        "def calculate_token_accuracy(predictions, references):\n",
        "    correct = 0  # Counter for correct tokens (matched between prediction and reference)\n",
        "    total = 0    # Counter for total number of tokens in predictions\n",
        "\n",
        "    for i in range(len(predictions)):\n",
        "        # Tokenize both predicted and reference sentences\n",
        "        pred_tokens = tokenize(predictions[i])  # e.g., ['the', 'cat', 'sat', 'on', 'the', 'mat']\n",
        "        ref_tokens = tokenize(references[i])    # e.g., ['the', 'cat', 'is', 'sitting', 'on', 'the', 'mat']\n",
        "\n",
        "        # Compare each predicted token to reference tokens (naive match)\n",
        "        for token in pred_tokens:\n",
        "            if token in ref_tokens:  # If the token exists anywhere in reference\n",
        "                correct += 1\n",
        "        total += len(pred_tokens)  # Update total with number of predicted tokens\n",
        "\n",
        "    # Calculate accuracy as percentage of correct matches\n",
        "    accuracy = (correct / total) * 100 if total > 0 else 0\n",
        "    return accuracy\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Call the function and print the result\n",
        "# -------------------------------------------------\n",
        "accuracy = calculate_token_accuracy(predictions, references)\n",
        "print(f\" Accuracy: {accuracy:.2f}%\")  # Output the token-level accuracy (e.g., 83.33%)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bagE_fbTn8NJ",
        "outputId": "a6165d90-2be1-47bb-c1a8-3daa717922fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 81.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUrKu063c-mE",
        "outputId": "b37bf54e-c1c2-42f8-d603-ff8656675a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=31cd9d4dbb11e303de5e4bf42eef68da77ba5bd0373a1666c62300fc9fd02a25\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer  # Import the ROUGE scorer from the rouge_score library\n",
        "\n",
        "# --------------------------------------------\n",
        "# Sample predicted and reference sentences\n",
        "# --------------------------------------------\n",
        "predictions = [\"the cat sat on the mat\", \"this is a test sentence\"]  # Model-generated output\n",
        "references = [\"the cat is sitting on the mat\", \"this is a test\"]      # Ground truth output\n",
        "\n",
        "# --------------------------------------------\n",
        "# Initialize the ROUGE scorer\n",
        "# --------------------------------------------\n",
        "# rouge1  = unigram (word-level) overlap\n",
        "# rouge2  = bigram (2-word sequence) overlap\n",
        "# rougeL  = longest common subsequence (LCS) overlap\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'])\n",
        "\n",
        "# --------------------------------------------\n",
        "# Loop through each prediction-reference pair\n",
        "# --------------------------------------------\n",
        "for i in range(len(predictions)):\n",
        "    prediction = predictions[i]  # Get the i-th predicted sentence\n",
        "    reference = references[i]    # Get the i-th reference sentence\n",
        "\n",
        "    # --------------------------------------------\n",
        "    # Compute ROUGE scores\n",
        "    # --------------------------------------------\n",
        "    # scorer.score(reference, prediction):\n",
        "    # - reference: actual ground truth sentence\n",
        "    # - prediction: sentence generated by model\n",
        "    score = scorer.score(reference, prediction)\n",
        "\n",
        "    # --------------------------------------------\n",
        "    # Print each ROUGE score result\n",
        "    # score['rouge1'], score['rouge2'], score['rougeL'] return namedtuples\n",
        "    # containing precision, recall, and F1 score\n",
        "    # --------------------------------------------\n",
        "    print(f\"ROUGE scores for Prediction {i + 1}:\")\n",
        "    print(f\"ROUGE-1: {score['rouge1']}\")  # Unigram overlap scores\n",
        "    print(f\"ROUGE-2: {score['rouge2']}\")  # Bigram overlap scores\n",
        "    print(f\"ROUGE-L: {score['rougeL']}\")  # Longest common subsequence scores\n",
        "    print(\"-------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M6nwrStnyHh",
        "outputId": "707dc669-1da1-408f-dfed-ee3594c8da7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE scores for Prediction 1:\n",
            "ROUGE-1: Score(precision=0.8333333333333334, recall=0.7142857142857143, fmeasure=0.7692307692307692)\n",
            "ROUGE-2: Score(precision=0.6, recall=0.5, fmeasure=0.5454545454545454)\n",
            "ROUGE-L: Score(precision=0.8333333333333334, recall=0.7142857142857143, fmeasure=0.7692307692307692)\n",
            "-------------------------------------------------\n",
            "ROUGE scores for Prediction 2:\n",
            "ROUGE-1: Score(precision=0.8, recall=1.0, fmeasure=0.888888888888889)\n",
            "ROUGE-2: Score(precision=0.75, recall=1.0, fmeasure=0.8571428571428571)\n",
            "ROUGE-L: Score(precision=0.8, recall=1.0, fmeasure=0.888888888888889)\n",
            "-------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# Example function for making a prediction with multiple inputs\n",
        "def make_prediction(model, input_sequence, decoder_input_sequence):\n",
        "    prediction = model.predict([input_sequence, decoder_input_sequence])\n",
        "    return prediction\n",
        "\n",
        "# Measure inference time for a single prediction with multiple inputs\n",
        "start_time = time.time()\n",
        "\n",
        "input_sequence = np.random.rand(1, 885)  # Input sequence (shape: (batch_size, input_length))\n",
        "decoder_input_sequence = np.random.rand(1, 36)  # Decoder input sequence (shape: (batch_size, decoder_input_length))\n",
        "\n",
        "# Make the prediction\n",
        "prediction = make_prediction(model, input_sequence, decoder_input_sequence)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate inference time\n",
        "inference_time = end_time - start_time\n",
        "print(f\"Inference Time for a Single Prediction: {inference_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVU4U8tLoi0Y",
        "outputId": "44558914-c4e8-4eab-f34c-bf9fed12f3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step\n",
            "Inference Time for a Single Prediction: 0.3076 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk  # Import the Natural Language Toolkit library for NLP evaluation\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction  # Import BLEU score tools\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Function to calculate BLEU score\n",
        "# Parameters:\n",
        "# - predictions: list of predicted token lists (e.g., [['hello', 'world']])\n",
        "# - references: list of reference token lists, each item is a list of one or more reference sequences\n",
        "# Returns:\n",
        "# - BLEU score (float)\n",
        "# ------------------------------------------------------------\n",
        "def calculate_bleu_and_meteor(predictions, references):\n",
        "    # Define a smoothing function to avoid zero scores for short sequences\n",
        "    smoothing = SmoothingFunction().method1\n",
        "\n",
        "    # Compute BLEU-4 score (up to 4-gram)\n",
        "    # weights=(0.25, 0.25, 0.25, 0.25): uniform weights for BLEU-4 (unigram to 4-gram)\n",
        "    # corpus_bleu expects references as a list of list-of-lists and predictions as list of lists\n",
        "    bleu_score = corpus_bleu(\n",
        "        references,              # list of true reference sentences (tokenized)\n",
        "        predictions,             # list of predicted sentences (tokenized)\n",
        "        smoothing_function=smoothing,  # apply smoothing to handle edge cases\n",
        "        weights=(0.25, 0.25, 0.25, 0.25)  # use BLEU-4 with equal weights for 1 to 4-grams\n",
        "    )\n",
        "\n",
        "    return bleu_score  # Return the computed BLEU score\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Example inputs for evaluation\n",
        "# predictions: predicted output sequences, tokenized as list of tokens\n",
        "# references: ground truth sequences, each sentence may have multiple reference variants\n",
        "# ------------------------------------------------------------\n",
        "predictions = [['hello', 'world'], ['this', 'is', 'test']]  # Example predicted sequences\n",
        "references = [[['hello', 'world']], [['this', 'is', 'test']]]  # Corresponding reference sequences\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Call the function to compute BLEU score using example data\n",
        "# ------------------------------------------------------------\n",
        "bleu_score = calculate_bleu_and_meteor(predictions, references)\n",
        "\n",
        "# Print the final BLEU score (4 decimal places)\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR9idhX9l9VI",
        "outputId": "f87d42ca-1468-4bb4-88de-a35a77623211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.3976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example scores for Accuracy, BLEU, and METEOR\n",
        "accuracy = 0.8333\n",
        "bleu = 0.3976\n",
        "\n",
        "# Create a list of the metrics and their values\n",
        "metrics = ['Accuracy', 'BLEU']\n",
        "scores = [accuracy, bleu]\n",
        "\n",
        "# Plotting the comparison graph\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(metrics, scores, color=['red', 'orange'])\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Comparison of Model Evaluation Metrics')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "abrZA7znqd4L",
        "outputId": "e8f858db-dbb0-4603-e2bb-1f49067e7092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **With Attention**"
      ],
      "metadata": {
        "id": "3FzaNJScdxHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "2g2mRvHGd2B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a sample CSV for demonstration\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdimUEy-d2OL",
        "outputId": "e310ebe3-4e55-41b5-d3e3-535bbe2ae58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              dialog                    act  \\\n",
            "0  ['Say , Jim , how about going for a few beers ...  [3 4 2 2 2 3 4 1 3 4]   \n",
            "1  ['Can you do push-ups ? '\\n \" Of course I can ...          [2 1 2 2 1 1]   \n",
            "2  ['Can you study with the radio on ? '\\n ' No ,...            [2 1 2 1 1]   \n",
            "3  ['Are you all right ? '\\n ' I will be all righ...              [2 1 1 1]   \n",
            "4  ['Hey John , nice skates . Are they new ? '\\n ...    [2 1 2 1 1 2 1 3 4]   \n",
            "\n",
            "                 emotion  \n",
            "0  [0 0 0 0 0 0 4 4 4 4]  \n",
            "1          [0 0 6 0 0 0]  \n",
            "2            [0 0 0 0 0]  \n",
            "3              [0 0 0 0]  \n",
            "4    [0 0 0 0 0 6 0 6 0]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch              # PyTorch library for tensor operations\n",
        "import torch.nn as nn     # Submodule for building neural network layers\n",
        "\n",
        "# Define an Encoder class using GRU (inherits from nn.Module)\n",
        "class Encoder(nn.Module):\n",
        "    # Constructor to initialize the encoder\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()  # Call the parent constructor\n",
        "\n",
        "        # input_dim: vocabulary size (number of unique tokens)\n",
        "        # emb_dim: dimension of the embedding vectors\n",
        "        # hidden_dim: number of features in the hidden state of the GRU\n",
        "        # n_layers: number of stacked GRU layers\n",
        "        # dropout: dropout probability for regularization between GRU layers\n",
        "\n",
        "        # Embedding layer to convert token indices to dense vectors\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        # GRU layer (Gated Recurrent Unit)\n",
        "        # Takes embeddings as input and outputs hidden states\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "\n",
        "        # Dropout layer to reduce overfitting\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # Forward pass of the encoder\n",
        "    def forward(self, src):\n",
        "        # src: source input sequence (shape: [sequence_length, batch_size])\n",
        "\n",
        "        # Apply embedding and dropout to the input sequence\n",
        "        embedded = self.dropout(self.embedding(src))  # shape: [seq_len, batch_size, emb_dim]\n",
        "\n",
        "        # Pass the embedded input through the GRU\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        # outputs: all hidden states from GRU (for attention, etc.), shape: [seq_len, batch_size, hidden_dim]\n",
        "        # hidden: final hidden state from the last GRU layer, shape: [n_layers, batch_size, hidden_dim]\n",
        "\n",
        "        return outputs, hidden  # Return both full outputs and final hidden state\n"
      ],
      "metadata": {
        "id": "hLEiJZ7Md2a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Bahdanau Attention mechanism as a PyTorch module\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n",
        "        super().__init__()  # Initialize the parent class\n",
        "\n",
        "        # enc_hidden_dim: Dimension of encoder's hidden state\n",
        "        # dec_hidden_dim: Dimension of decoder's hidden state\n",
        "\n",
        "        # Linear layer to combine encoder and decoder hidden states\n",
        "        self.attn = nn.Linear(enc_hidden_dim + dec_hidden_dim, dec_hidden_dim)\n",
        "\n",
        "        # Learnable parameter vector v used to compute attention scores\n",
        "        self.v = nn.Parameter(torch.rand(dec_hidden_dim))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden: decoder hidden state at current time step (shape: [n_layers, batch_size, dec_hidden_dim])\n",
        "        # encoder_outputs: all encoder outputs for each time step (shape: [src_len, batch_size, enc_hidden_dim])\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]  # Get batch size\n",
        "        src_len = encoder_outputs.shape[0]     # Get source sequence length\n",
        "\n",
        "        # Repeat the last decoder hidden state across all time steps (shape: [src_len, batch_size, dec_hidden_dim])\n",
        "        hidden = hidden[-1].repeat(src_len, 1, 1)\n",
        "\n",
        "        # Concatenate encoder_outputs and repeated decoder hidden states (along last dim)\n",
        "        # Then pass through a tanh-activated linear layer to compute energy scores\n",
        "        # energy shape: [src_len, batch_size, dec_hidden_dim]\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "\n",
        "        # Rearrange dimensions to prepare for batch matrix multiplication\n",
        "        # energy shape becomes: [batch_size, dec_hidden_dim, src_len]\n",
        "        energy = energy.permute(1, 2, 0)\n",
        "\n",
        "        # Repeat vector v for each batch and reshape for batch matrix multiplication\n",
        "        # v shape: [batch_size, 1, dec_hidden_dim]\n",
        "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
        "\n",
        "        # Compute attention scores: batch matrix multiply v and energy\n",
        "        # attention shape: [batch_size, src_len]\n",
        "        attention = torch.bmm(v, energy).squeeze(1)\n",
        "\n",
        "        # Apply softmax to normalize attention scores across the source sequence\n",
        "        return torch.softmax(attention, dim=1)  # shape: [batch_size, src_len]\n"
      ],
      "metadata": {
        "id": "2eo5MtYxd2m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Luong Attention mechanism as a PyTorch module\n",
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()  # Initialize the parent class\n",
        "\n",
        "        # hidden_dim: Dimension of the hidden state of the decoder\n",
        "\n",
        "        # Linear layer to project the decoder output into the same space as the encoder output\n",
        "        self.attn = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, decoder_output, encoder_outputs):\n",
        "        # decoder_output: Output of the decoder at the current time step (shape: [batch_size, hidden_dim])\n",
        "        # encoder_outputs: All encoder outputs (shape: [src_len, batch_size, hidden_dim])\n",
        "\n",
        "        # Calculate attention energies: batch matrix multiplication (BMM)\n",
        "        # encoder_outputs.transpose(0, 1): Shape changes from [src_len, batch_size, hidden_dim]\n",
        "        # to [batch_size, src_len, hidden_dim], allowing batch-wise multiplication with decoder output\n",
        "        # decoder_output.unsqueeze(2): Adds an extra dimension to decoder output, changing shape from [batch_size, hidden_dim] to [batch_size, hidden_dim, 1]\n",
        "        # attn_energies shape: [batch_size, src_len], which is the raw attention scores\n",
        "        attn_energies = torch.bmm(encoder_outputs.transpose(0, 1),\n",
        "                                  decoder_output.unsqueeze(2)).squeeze(2)\n",
        "\n",
        "        # Apply softmax over the attention energies to get the normalized attention weights\n",
        "        # The result will be a probability distribution across the source sequence (shape: [batch_size, src_len])\n",
        "        return torch.softmax(attn_energies, dim=1)\n"
      ],
      "metadata": {
        "id": "hsDG0hL5d2ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Decoder class which uses attention mechanism, GRU, and fully connected layer to generate predictions\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hidden_dim, dec_hidden_dim, attention, n_layers, dropout):\n",
        "        super().__init__()  # Initialize the parent class (nn.Module)\n",
        "\n",
        "        # Parameters:\n",
        "        # output_dim: Size of the output vocabulary (number of words in the output language)\n",
        "        # emb_dim: Embedding dimension (size of the word embeddings)\n",
        "        # enc_hidden_dim: Size of the hidden state of the encoder\n",
        "        # dec_hidden_dim: Size of the hidden state of the decoder\n",
        "        # attention: Attention mechanism (e.g., Bahdanau or Luong attention)\n",
        "        # n_layers: Number of GRU layers in the decoder\n",
        "        # dropout: Dropout rate to prevent overfitting\n",
        "\n",
        "        self.output_dim = output_dim  # Set the output dimension (vocabulary size)\n",
        "        self.attention = attention  # Initialize the attention mechanism\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)  # Word embedding layer (mapping words to vectors)\n",
        "        self.rnn = nn.GRU(enc_hidden_dim + emb_dim, dec_hidden_dim, n_layers, dropout=dropout)  # GRU layer for RNN\n",
        "        self.fc_out = nn.Linear(enc_hidden_dim + dec_hidden_dim + emb_dim, output_dim)  # Linear layer to output the prediction\n",
        "        self.dropout = nn.Dropout(dropout)  # Dropout layer to apply during training\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        # input: Current word from the target sequence (shape: [batch_size])\n",
        "        # hidden: The current hidden state from the previous decoder step (shape: [n_layers, batch_size, dec_hidden_dim])\n",
        "        # encoder_outputs: The outputs from the encoder (shape: [src_len, batch_size, enc_hidden_dim])\n",
        "\n",
        "        input = input.unsqueeze(0)  # Add a batch dimension to input (shape: [1, batch_size])\n",
        "        embedded = self.dropout(self.embedding(input))  # Pass the input word through the embedding layer and apply dropout\n",
        "\n",
        "        # Calculate attention weights based on the current hidden state and the encoder outputs\n",
        "        attn_weights = self.attention(hidden, encoder_outputs)  # Attention scores (shape: [batch_size, src_len])\n",
        "        attn_weights = attn_weights.unsqueeze(1)  # Add extra dimension for matrix multiplication (shape: [batch_size, 1, src_len])\n",
        "\n",
        "        # Compute the context vector by applying attention weights to the encoder outputs\n",
        "        context = torch.bmm(attn_weights, encoder_outputs.transpose(0, 1))  # Context vector (shape: [batch_size, 1, enc_hidden_dim])\n",
        "        context = context.transpose(0, 1)  # Transpose to get the shape [1, batch_size, enc_hidden_dim]\n",
        "\n",
        "        # Concatenate the embedded input with the context vector\n",
        "        rnn_input = torch.cat((embedded, context), dim=2)  # Combine the context with the embedded input (shape: [1, batch_size, emb_dim + enc_hidden_dim])\n",
        "\n",
        "        # Pass the combined input through the GRU to get the output and new hidden state\n",
        "        output, hidden = self.rnn(rnn_input, hidden)  # GRU output and hidden state (shape: [1, batch_size, dec_hidden_dim])\n",
        "\n",
        "        # Calculate the prediction by passing the GRU output, context, and embedded input through the fully connected layer\n",
        "        prediction = self.fc_out(torch.cat((output, context, embedded), dim=2).squeeze(0))  # Prediction (shape: [batch_size, output_dim])\n",
        "\n",
        "        return prediction, hidden, attn_weights  # Return the prediction, updated hidden state, and attention weights"
      ],
      "metadata": {
        "id": "nw0M1yy2esZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "955vYoEzes-T",
        "outputId": "e19dd317-b85b-47f9-e0e9-1c0215f1eb4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.3.0->torchtext)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.3.0->torchtext)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.3.0->torchtext)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.3.0->torchtext)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.3.0->torchtext)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.3.0->torchtext)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.3.0->torchtext)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.2)\n",
            "Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m777.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchtext\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchtext-0.18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "fff4ad4e09ee4948871cbee7a4086d15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries from NLTK for calculating BLEU score\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu  # Import BLEU score calculation functions\n",
        "\n",
        "# Download tokenizer resources if needed (used by nltk for tokenization)\n",
        "nltk.download('punkt')  # This ensures the necessary tokenizer resources are downloaded\n",
        "\n",
        "# Example BLEU score usage\n",
        "# The reference is a list of lists, where each inner list represents a set of one or more reference translations\n",
        "reference = [['hi', 'how', 'are', 'you']]  # The true or reference translation(s) of the sentence\n",
        "# The candidate is a list that contains the predicted translation from the model\n",
        "candidate = ['hi', 'how', 'are', 'you']  # The predicted translation from the model\n",
        "\n",
        "# Calculate the BLEU score for the candidate against the reference\n",
        "# sentence_bleu takes in the reference and candidate as inputs and calculates the BLEU score for the sentence\n",
        "print(\"BLEU score:\", sentence_bleu(reference, candidate))  # Prints the BLEU score for the candidate translation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxaZOpiwetB7",
        "outputId": "893f9f07-eb55-4bd0-d4f1-643cbe074112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the references and candidates\n",
        "# References are lists of lists, where each inner list is a set of one or more valid translations for a sentence\n",
        "# In this case, for the sentence \"hello there\", we have two possible reference translations: \"hello there\" and \"hi there\"\n",
        "references = [[['hello', 'there'], ['hi', 'there']]]  # List of reference translations for the sentence\n",
        "\n",
        "# Candidates are the predicted translations by the model\n",
        "# Here, the model predicted the translation \"hello there\"\n",
        "candidates = [['hello', 'there']]  # List of model's predicted translations\n",
        "\n",
        "# Calculate the BLEU score for the entire corpus (all sentences) using the corpus_bleu function\n",
        "# corpus_bleu compares a list of reference translations to a list of predicted translations (i.e., candidates) for multiple sentences\n",
        "# In this case, we have one sentence in the corpus\n",
        "score = corpus_bleu(references, candidates)  # Calculating BLEU score for the corpus\n",
        "\n",
        "# Print the BLEU score for the corpus (it tells how similar the candidates are to the reference translations)\n",
        "print(\"Corpus BLEU:\", score)  # Output the BLEU score for the corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXskDWuue6iV",
        "outputId": "7014d14a-8329-427a-a033-89e870164d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus BLEU: 1.491668146240062e-154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for plotting\n",
        "import matplotlib.pyplot as plt  # Matplotlib is used for creating static, animated, and interactive visualizations\n",
        "import seaborn as sns  # Seaborn is built on top of Matplotlib and provides a high-level interface for drawing attractive statistical graphics\n",
        "\n",
        "# Function to display attention heatmap\n",
        "def display_attention(sentence, translation, attention):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - sentence (list): List of words in the source sentence (the input to the model)\n",
        "    - translation (list): List of words in the predicted translation (the model output)\n",
        "    - attention (2D array or tensor): Attention weights (a matrix representing the attention between source and target words)\n",
        "    \"\"\"\n",
        "    # Create a figure with a size of 10x10 inches\n",
        "    fig = plt.figure(figsize=(10,10))  # This sets the dimensions of the figure (plot area) for the heatmap\n",
        "\n",
        "    # Create the heatmap using Seaborn, which will show the attention scores\n",
        "    # `attention` is a 2D matrix where each element represents the attention score between a word in the source sentence\n",
        "    # and a word in the predicted sentence. The `xticklabels` and `yticklabels` will be the words from the source and predicted sentences.\n",
        "    sns.heatmap(attention, xticklabels=sentence, yticklabels=translation, cmap='viridis')\n",
        "\n",
        "    # Label the x-axis as 'Source Sentence', indicating that it represents words from the source sentence\n",
        "    plt.xlabel('Source Sentence')\n",
        "\n",
        "    # Label the y-axis as 'Predicted Sentence', indicating that it represents words from the model's output sentence\n",
        "    plt.ylabel('Predicted Sentence')\n",
        "\n",
        "    # Display the plot (this is necessary for showing the heatmap)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lG2gqLNce7NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from nltk.translate.meteor_score import meteor_score  # METEOR score calculation function\n",
        "from nltk.translate.bleu_score import sentence_bleu  # BLEU score calculation function\n",
        "from rouge_score import rouge_scorer  # ROUGE score calculation function\n",
        "\n",
        "# Function to compute BLEU, ROUGE, and METEOR scores\n",
        "def compute_metrics(reference, candidate):\n",
        "    \"\"\"\n",
        "    Computes the BLEU, ROUGE-1, ROUGE-L, and METEOR scores between the reference and candidate translations.\n",
        "\n",
        "    Parameters:\n",
        "    - reference (list): List of words in the reference sentence (true target sentence)\n",
        "    - candidate (list): List of words in the candidate sentence (model's prediction)\n",
        "\n",
        "    Returns:\n",
        "    - Dictionary containing the BLEU, ROUGE-1, ROUGE-L, and METEOR scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # BLEU Score Calculation\n",
        "    bleu = sentence_bleu([reference], candidate)  # Compute BLEU score (uses precision of n-grams)\n",
        "    # [reference] is passed as a list of lists since the `sentence_bleu` function expects a list of references\n",
        "\n",
        "    # ROUGE Score Calculation\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)  # Initialize ROUGE scorer with ROUGE-1 and ROUGE-L metrics\n",
        "    # use_stemmer=True applies stemming to words (e.g., \"running\" and \"run\" are treated the same)\n",
        "    rouge_scores = scorer.score(' '.join(reference), ' '.join(candidate))  # Compute ROUGE score by joining words into a sentence string\n",
        "\n",
        "    # METEOR Score Calculation\n",
        "    meteor = meteor_score([reference], candidate)  # Compute METEOR score (measures precision, recall, synonymy, etc.)\n",
        "\n",
        "    # Return the computed scores in a dictionary\n",
        "    return {\n",
        "        'BLEU': bleu,  # BLEU score for n-gram precision\n",
        "        'ROUGE-1': rouge_scores['rouge1'].fmeasure,  # ROUGE-1 F1 score\n",
        "        'ROUGE-L': rouge_scores['rougeL'].fmeasure,  # ROUGE-L F1 score (longest common subsequence)\n",
        "        'METEOR': meteor  # METEOR score (combines precision, recall, synonymy, and stemming)\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "ref = ['hello', 'how', 'are', 'you']  # Reference sentence (true target)\n",
        "cand = ['hello', 'how', 'are', 'you']  # Candidate sentence (model's prediction)\n",
        "print(compute_metrics(ref, cand))  # Call the function and print the computed metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmCmN_X5fDps",
        "outputId": "d8186166-3c4a-40ee-b175-8646fd0af617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'BLEU': 1.0, 'ROUGE-1': 1.0, 'ROUGE-L': 1.0, 'METEOR': 0.9921875}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self Attention"
      ],
      "metadata": {
        "id": "lMapLZbnfubr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf  # TensorFlow library for deep learning\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # For converting text to sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # For padding sequences to fixed length\n",
        "from tensorflow.keras.models import Model  # For creating Keras models\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, LayerNormalization, Dropout  # Keras layers to build the model\n",
        "from tensorflow.keras.layers import Layer  # For creating custom layers\n",
        "from tensorflow.keras.layers import Lambda  # For custom Lambda layers in Keras\n",
        "import numpy as np  # NumPy for array manipulation\n",
        "\n",
        "# Prepare data: Get sample inputs from train_df\n",
        "texts = train_df['dialog'].astype(str).tolist()[:1000]  # Get the 'dialog' column from train_df, convert to list and take the first 1000 examples\n",
        "\n",
        "# Tokenize\n",
        "tokenizer = Tokenizer()  # Initialize the Tokenizer to process text and convert words to integer indices\n",
        "tokenizer.fit_on_texts(texts)  # Fit the tokenizer on the text data to create a word index based on frequency\n",
        "sequences = tokenizer.texts_to_sequences(texts)  # Convert each text in 'texts' to a sequence of integers (word indices)\n",
        "padded = pad_sequences(sequences, padding='post')  # Pad sequences to the same length (post-padding), ensuring uniform input size\n",
        "vocab_size = len(tokenizer.word_index) + 1  # The size of the vocabulary, including padding (add 1 to account for the padding token)\n",
        "\n",
        "# Custom Self-Attention Layer\n",
        "class SelfAttention(Layer):\n",
        "    \"\"\"\n",
        "    Custom self-attention mechanism that computes attention scores and applies them to the input sequence.\n",
        "\n",
        "    Parameters:\n",
        "    - units (int): The number of units (dimensions) of the output attention layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, units):\n",
        "        super(SelfAttention, self).__init__()  # Initialize the base Layer class\n",
        "        self.units = units  # Set the number of units for the attention output\n",
        "        self.Wq = Dense(units)  # Dense layer to compute query vectors\n",
        "        self.Wk = Dense(units)  # Dense layer to compute key vectors\n",
        "        self.Wv = Dense(units)  # Dense layer to compute value vectors\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Perform the forward pass of the self-attention mechanism.\n",
        "\n",
        "        Parameters:\n",
        "        - inputs (Tensor): The input tensor to the attention layer (batch_size, sequence_length, embedding_dim).\n",
        "\n",
        "        Returns:\n",
        "        - output (Tensor): The output tensor after applying attention (batch_size, sequence_length, units).\n",
        "        \"\"\"\n",
        "        Q = self.Wq(inputs)  # Compute query vectors (Q)\n",
        "        K = self.Wk(inputs)  # Compute key vectors (K)\n",
        "        V = self.Wv(inputs)  # Compute value vectors (V)\n",
        "\n",
        "        # Compute attention scores using the dot product of Q and K (scaled by sqrt(units))\n",
        "        scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(tf.cast(self.units, tf.float32))\n",
        "\n",
        "        # Apply softmax to the scores to obtain the attention weights\n",
        "        weights = tf.nn.softmax(scores, axis=-1)  # Softmax normalization along the last axis (sequence length)\n",
        "\n",
        "        # Multiply the attention weights with the value vectors (V) to get the final output\n",
        "        output = tf.matmul(weights, V)  # Perform the weighted sum of value vectors\n",
        "\n",
        "        return output  # Return the output of the attention mechanism\n",
        "\n",
        "# Define the model\n",
        "input_layer = Input(shape=(padded.shape[1],))  # Define the input layer with shape (sequence_length,). Padded sequence length is padded.shape[1].\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=64)(input_layer)  # Embedding layer that maps each word index to a 64-dimensional vector\n",
        "\n",
        "# Apply the custom self-attention layer to the embedding output\n",
        "attention_output = SelfAttention(64)(embedding_layer)  # Self-attention with 64 units applied to the embedding output\n",
        "\n",
        "# Apply a Lambda layer to pool the attention output across the sequence (average the sequence dimensions)\n",
        "pooled = Lambda(lambda x: tf.reduce_mean(x, axis=1))(attention_output)  # Compute the mean over the sequence dimension (axis=1)\n",
        "\n",
        "# Define the output layer for binary classification (sigmoid activation for 0/1 output)\n",
        "output_layer = Dense(1, activation='sigmoid')(pooled)  # Output layer with one unit and sigmoid activation for binary classification\n",
        "\n",
        "# Create the model by specifying input and output layers\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model with Adam optimizer and binary cross-entropy loss function\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Display the model summary to show the architecture of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "C3ymkUqcf0uh",
        "outputId": "8a6440d1-8496-47cb-81cb-aa0c8a167fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m621\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m621\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m393,984\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ self_attention (\u001b[38;5;33mSelfAttention\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m621\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m12,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">621</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">621</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,984</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ self_attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">621</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m406,529\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">406,529</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m406,529\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">406,529</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np  # NumPy for array manipulations\n",
        "import tensorflow as tf  # TensorFlow for deep learning\n",
        "from tensorflow.keras.layers import Layer, Input, Embedding, Dense  # Keras layers to build the model\n",
        "from tensorflow.keras.models import Model  # Keras model class to build a neural network model\n",
        "import matplotlib.pyplot as plt  # Matplotlib for plotting the attention heatmap\n",
        "import seaborn as sns  # Seaborn for enhanced heatmap visualizations\n",
        "\n",
        "MAX_LEN = 20  # Maximum sequence length for input data\n",
        "\n",
        "# 1. Self-Attention Layer (standalone, returns weights)\n",
        "class SelfAttention(Layer):\n",
        "    \"\"\"\n",
        "    Custom Self-Attention Layer that computes attention scores and context vectors.\n",
        "\n",
        "    Parameters:\n",
        "    - hidden_size (int): The number of units for query, key, and value vectors.\n",
        "    - return_attention (bool): Whether to return attention weights along with the context vector.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size, return_attention=False):\n",
        "        super(SelfAttention, self).__init__()  # Initialize the parent Layer class\n",
        "        self.hidden_size = hidden_size  # Set hidden size for query, key, and value vectors\n",
        "        self.return_attention = return_attention  # Flag to return attention weights\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        Initialize the weights for query (Q), key (K), and value (V) matrices.\n",
        "\n",
        "        Parameters:\n",
        "        - input_shape (tuple): The shape of the input tensor, excluding the batch size.\n",
        "        \"\"\"\n",
        "        # Create weights for Q, K, and V. Each weight matrix has dimensions (input_shape[-1], hidden_size)\n",
        "        self.W_q = self.add_weight(shape=(input_shape[-1], self.hidden_size), initializer='glorot_uniform', trainable=True)\n",
        "        self.W_k = self.add_weight(shape=(input_shape[-1], self.hidden_size), initializer='glorot_uniform', trainable=True)\n",
        "        self.W_v = self.add_weight(shape=(input_shape[-1], self.hidden_size), initializer='glorot_uniform', trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Perform the self-attention calculation.\n",
        "\n",
        "        Parameters:\n",
        "        - inputs (Tensor): Input tensor (batch_size, seq_len, input_dim).\n",
        "\n",
        "        Returns:\n",
        "        - context (Tensor): The context vector after applying attention weights to the value vectors.\n",
        "        - attention_weights (Tensor, optional): The computed attention weights (if return_attention=True).\n",
        "        \"\"\"\n",
        "        # Compute query (Q), key (K), and value (V) vectors by applying the corresponding weight matrices\n",
        "        Q = tf.matmul(inputs, self.W_q)  # (batch_size, seq_len, hidden_size)\n",
        "        K = tf.matmul(inputs, self.W_k)  # (batch_size, seq_len, hidden_size)\n",
        "        V = tf.matmul(inputs, self.W_v)  # (batch_size, seq_len, hidden_size)\n",
        "\n",
        "        # Compute attention scores using scaled dot-product attention\n",
        "        scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(tf.cast(self.hidden_size, tf.float32))  # (batch_size, seq_len, seq_len)\n",
        "\n",
        "        # Apply softmax to the attention scores to get the attention weights\n",
        "        attention_weights = tf.nn.softmax(scores, axis=-1)  # (batch_size, seq_len, seq_len)\n",
        "\n",
        "        # Compute the context vector by applying the attention weights to the value vectors\n",
        "        context = tf.matmul(attention_weights, V)  # (batch_size, seq_len, hidden_size)\n",
        "\n",
        "        if self.return_attention:\n",
        "            return context, attention_weights  # Return both context and attention weights if requested\n",
        "        return context  # Return only the context vector\n",
        "\n",
        "# 2. Model Setup\n",
        "vocab_size = 1000  # The size of the vocabulary (number of unique tokens)\n",
        "embedding_dim = 64  # The dimensionality of the embedding space (each word will be represented as a 64-dimensional vector)\n",
        "seq_len = 20  # The maximum length of input sequences (fixed length)\n",
        "\n",
        "# Define the input layer with a shape corresponding to the sequence length\n",
        "inputs = Input(shape=(seq_len,))  # Input shape is (batch_size, seq_len), each sequence is a list of token IDs\n",
        "\n",
        "# Create the embedding layer that converts word indices to embedding vectors\n",
        "embedding = Embedding(vocab_size, embedding_dim)(inputs)  # Convert input token IDs into dense vectors of size embedding_dim\n",
        "\n",
        "# Apply the Self-Attention layer, specifying the hidden size and that we want to return the attention weights\n",
        "attention_layer = SelfAttention(hidden_size=64, return_attention=True)\n",
        "attention_output, attention_weights = attention_layer(embedding)  # Get both attention outputs and attention weights\n",
        "\n",
        "# Use Lambda layer to perform pooling (mean reduction) over the sequence dimension (axis=1)\n",
        "from tensorflow.keras.layers import Lambda\n",
        "pooled = Lambda(lambda x: tf.reduce_mean(x, axis=1))(attention_output)  # Reduce the sequence dimension by averaging\n",
        "\n",
        "# Define the output layer with a sigmoid activation for binary classification\n",
        "output = Dense(1, activation='sigmoid')(pooled)  # Output layer with one unit and sigmoid activation\n",
        "\n",
        "# Build the model by specifying the input and output layers\n",
        "model = Model(inputs=inputs, outputs=[output, attention_weights])  # Model that returns both the output and attention weights\n",
        "\n",
        "# Compile the model with the Adam optimizer and binary cross-entropy loss\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# 3. Dummy data\n",
        "sample_input = np.random.randint(0, vocab_size, size=(1, seq_len))  # Create a random input sequence with shape (1, seq_len)\n",
        "_ , attention = model.predict(sample_input)  # Predict using the model, only retrieve attention weights (ignore the output)\n",
        "\n",
        "# 4. Attention Visualization\n",
        "def plot_attention(attention_weights, input_tokens):\n",
        "    \"\"\"\n",
        "    Visualizes the attention weights using a heatmap.\n",
        "\n",
        "    Parameters:\n",
        "    - attention_weights (Tensor): The attention weights from the Self-Attention layer.\n",
        "    - input_tokens (list): A list of tokens corresponding to the input sequence for labeling the heatmap axes.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 8))  # Set the figure size for the plot\n",
        "    sns.heatmap(attention_weights, xticklabels=input_tokens, yticklabels=input_tokens, cmap='viridis')  # Plot the heatmap of attention weights\n",
        "    plt.title(\"Self-Attention Weights\")  # Title of the plot\n",
        "    plt.xlabel(\"Key\")  # Label for the x-axis (keys)\n",
        "    plt.ylabel(\"Query\")  # Label for the y-axis (queries)\n",
        "    plt.show()  # Display the plot\n",
        "\n",
        "# Create a list of tokens representing the input sequence for the heatmap labels\n",
        "input_tokens = [f\"tok_{i}\" for i in range(seq_len)]  # Example tokens, e.g., tok_0, tok_1, ..., tok_19\n",
        "\n",
        "# Plot the attention weights for the given input tokens\n",
        "plot_attention(attention[0], input_tokens)  # Visualize the attention weights for the first sample input\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "id": "bQ5NgXj7f07X",
        "outputId": "ed801ae0-18a3-4ce0-db61-00d826e52d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer  # Import Tokenizer from Keras for text tokenization\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # Import pad_sequences from Keras for padding sequences\n",
        "from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder from scikit-learn to encode labels\n",
        "import re  # Import the regular expression module for string manipulation\n",
        "\n",
        "# 1. Function to parse and format the 'act' column\n",
        "def parse_act(act_str):\n",
        "    \"\"\"\n",
        "    Parses the string representation of a list of actions (acts) and ensures that commas are added\n",
        "    between numbers if missing.\n",
        "\n",
        "    Parameters:\n",
        "    - act_str (str): The string containing the list of actions, which might lack commas between numbers.\n",
        "\n",
        "    Returns:\n",
        "    - list: The parsed and formatted list of actions.\n",
        "    \"\"\"\n",
        "    act_str = re.sub(r'(?<=\\d)\\s+(?=\\d)', ', ', act_str.strip())  # Add commas between numbers if missing\n",
        "    return eval(act_str)  # Use eval to convert the string representation of the list into a Python list\n",
        "\n",
        "# 2. Tokenize dialogs\n",
        "dialogs = train_df['dialog'].apply(lambda x: ' '.join(eval(x)))  # Convert the list-like string in 'dialog' column into a proper string of words\n",
        "tokenizer = Tokenizer(oov_token='<OOV>')  # Initialize the Tokenizer with an out-of-vocabulary (OOV) token\n",
        "tokenizer.fit_on_texts(dialogs)  # Fit the tokenizer on the dialog texts to create the word index\n",
        "sequences = tokenizer.texts_to_sequences(dialogs)  # Convert each dialog into a sequence of integers based on the word index\n",
        "\n",
        "# 3. Pad sequences to fixed length\n",
        "MAX_LEN = 50  # Set the maximum length of the sequences (padding or truncating to this length)\n",
        "padded = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "# Pad or truncate the sequences to a fixed length (MAX_LEN)\n",
        "# - `maxlen=MAX_LEN`: Defines the maximum length of the sequences.\n",
        "# - `padding='post'`: Pads sequences at the end.\n",
        "# - `truncating='post'`: Truncates sequences at the end if they exceed MAX_LEN.\n",
        "\n",
        "# 4. Encode labels (acts or emotions)\n",
        "label_encoder = LabelEncoder()  # Initialize LabelEncoder to encode labels (acts/emotions)\n",
        "# Apply to column and get last act\n",
        "labels = train_df['act'].apply(lambda x: parse_act(x)[-1])  # Get the last action from the list of actions in the 'act' column\n",
        "\n",
        "# 5. Function to clean and convert 'act' column into lists of integers\n",
        "def parse_act_column(act_str):\n",
        "    \"\"\"\n",
        "    Parses the 'act' column, removing brackets and splitting the string by spaces to convert it into\n",
        "    a list of integers representing actions.\n",
        "\n",
        "    Parameters:\n",
        "    - act_str (str): The string representation of a list of integers in the 'act' column.\n",
        "\n",
        "    Returns:\n",
        "    - list: The list of integers corresponding to the actions.\n",
        "    \"\"\"\n",
        "    act_str = act_str.strip(\"[]\")  # Remove brackets around the string\n",
        "    act_list = re.split(r'\\s+', act_str)  # Split the string by one or more spaces\n",
        "    return list(map(int, act_list))  # Convert each split value to an integer\n",
        "\n",
        "# 6. Apply the function to the 'act' column to get a list of actions for each entry\n",
        "train_acts = train_df['act'].apply(parse_act_column)  # Apply the parse_act_column function to the 'act' column\n",
        "\n",
        "# 7. Get the last act from each list of acts\n",
        "last_acts = train_acts.apply(lambda x: x[-1])  # For each list of acts, retrieve the last action\n",
        "\n",
        "# 8. Fit the LabelEncoder\n",
        "label_encoder = LabelEncoder()  # Initialize the LabelEncoder again (after processing)\n",
        "labels = label_encoder.fit_transform(last_acts)  # Fit the LabelEncoder on the last acts and transform them into numeric labels\n"
      ],
      "metadata": {
        "id": "1OeJXoJjf1JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Lambda\n",
        "import tensorflow as tf\n",
        "\n",
        "class SelfAttention(tf.keras.layers.Layer):  # Create a custom Keras layer for self-attention\n",
        "    def __init__(self, units):\n",
        "        \"\"\"\n",
        "        Initialize the Self-Attention layer.\n",
        "\n",
        "        Parameters:\n",
        "        - units (int): Dimensionality of the intermediate dense layers for computing attention.\n",
        "        \"\"\"\n",
        "        super(SelfAttention, self).__init__()  # Call the base class constructor\n",
        "        self.W1 = Dense(units)  # First Dense layer for attention scoring\n",
        "        self.W2 = Dense(units)  # Second Dense layer for attention scoring\n",
        "        self.V = Dense(1)       # Output layer to generate a single attention score per word\n",
        "\n",
        "\n",
        "    def call(self, values):\n",
        "        \"\"\"\n",
        "        Forward pass for the attention mechanism.\n",
        "\n",
        "        Parameters:\n",
        "        - values (Tensor): Input embeddings of shape (batch_size, sequence_length, embedding_dim)\n",
        "\n",
        "        Returns:\n",
        "        - context_vector (Tensor): Weighted sum of input embeddings, representing important context\n",
        "        \"\"\"\n",
        "        score = tf.nn.tanh(self.W1(values) + self.W2(values))  # Compute attention scores (shape: batch_size, seq_len, units)\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1)  # Normalize scores to get attention weights (shape: batch_size, seq_len, 1)\n",
        "        context_vector = attention_weights * values  # Multiply weights with input embeddings (element-wise)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)  # Sum over time dimension (seq_len) to get context vector\n",
        "        return context_vector  # Output shape: (batch_size, embedding_dim)\n",
        "\n",
        "\n",
        "# Build model\n",
        "input_layer = Input(shape=(MAX_LEN,))\n",
        "# - shape=(MAX_LEN,): Sequence length (each input is a sequence of word indices of fixed length MAX_LEN)\n",
        "embedding_layer = Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=64)(input_layer)\n",
        "attention_output = SelfAttention(64)(embedding_layer)\n",
        "output_layer = Dense(len(label_encoder.classes_), activation='softmax')(attention_output)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "M6nvns9CggTv",
        "outputId": "4bfa8f07-0a22-4928-ad7a-d083a26a5c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │     \u001b[38;5;34m1,164,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ self_attention_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,385\u001b[0m │\n",
              "│ (\u001b[38;5;33mSelfAttention\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,164,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ self_attention_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,385</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,172,805\u001b[0m (4.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,172,805</span> (4.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,172,805\u001b[0m (4.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,172,805</span> (4.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference Speed"
      ],
      "metadata": {
        "id": "1_k6e9Yphrw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time  # Import time module to track training duration\n",
        "\n",
        "start = time.time()  # Record start time before training begins\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    padded,                 # Input data: padded sequences of tokenized dialogs\n",
        "    labels,                 # Target labels: integer-encoded final acts\n",
        "    epochs=5,               # Number of times to iterate over the entire dataset\n",
        "    batch_size=32           # Number of samples per gradient update\n",
        ")\n",
        "\n",
        "training_time = time.time() - start  # Calculate total training time\n",
        "\n",
        "print(f\"Training time: {training_time:.2f} seconds\")  # Display how long training took\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o4i00gTgg0K",
        "outputId": "e2da69c8-a7c1-4846-84bd-4a08d9f1b62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.6305 - loss: 1.0446\n",
            "Epoch 2/5\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6454 - loss: 0.9486\n",
            "Epoch 3/5\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6495 - loss: 0.9202\n",
            "Epoch 4/5\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6528 - loss: 0.8670\n",
            "Epoch 5/5\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6838 - loss: 0.7718\n",
            "Training time: 12.18 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical  # For converting integer labels to one-hot vectors\n",
        "\n",
        "# Prepare test data\n",
        "X_test = tokenizer.texts_to_sequences(test_df['dialog'])  # Convert test dialog text into sequences of token indices using the trained tokenizer\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=50)  # Pad or truncate sequences to fixed length (post-padding, max length 50)\n",
        "\n",
        "# Label encode the target variable (dialog acts)\n",
        "y_test_acts = test_df['act'].apply(lambda x: parse_act(x)[-1])  # Extract the last act from each dialog's act list in test set\n",
        "y_test = label_encoder.transform(y_test_acts)  # Convert string/integer labels into encoded integers using the fitted label encoder\n",
        "\n",
        "# One-hot encode the labels (only if needed for categorical loss; not needed for sparse categorical loss)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=len(label_encoder.classes_))\n",
        "# Converts integer labels to one-hot vectors; 'num_classes' ensures correct number of output classes\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred_proba = model.predict(X_test)  # Get predicted class probabilities for test data\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)  # Select the index (class) with the highest predicted probability\n",
        "\n",
        "# Accuracy score\n",
        "from sklearn.metrics import accuracy_score  # Import accuracy evaluation function\n",
        "accuracy = accuracy_score(y_test, y_pred)  # Compare predicted labels with true labels\n",
        "print(f\"Accuracy: {accuracy:.4f}\")  # Print accuracy rounded to 4 decimal places\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRgekxxmhwFo",
        "outputId": "19f6a7f8-477e-4de4-dc75-cb979ca6189e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step\n",
            "Accuracy: 0.5790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction  # Import BLEU score computation and smoothing from NLTK\n",
        "\n",
        "# Example: reference and candidate sentences\n",
        "references = [[\"hello\", \"how\", \"are\", \"you\"]]  # List of reference sentences (ground truth), each reference is a list of tokens\n",
        "candidates = [[\"hi\", \"how\", \"you\"]]  # List of candidate (predicted) sentences, each candidate is a list of tokens\n",
        "\n",
        "# Apply smoothing to BLEU score\n",
        "smooth_fn = SmoothingFunction().method1  # Select a smoothing method to avoid BLEU score being 0 when n-grams are missing\n",
        "\n",
        "# Compute BLEU score with smoothing\n",
        "bleu = sentence_bleu(references, candidates[0], smoothing_function=smooth_fn)\n",
        "# sentence_bleu(): computes BLEU score\n",
        "# parameters:\n",
        "#   references – list of reference translations (list of token lists)\n",
        "#   candidates[0] – candidate translation (list of tokens)\n",
        "#   smoothing_function – smoothing function to handle zero counts in short sequences\n",
        "\n",
        "print(f\"BLEU score with smoothing: {bleu:.4f}\")  # Print BLEU score rounded to 4 decimal places"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsCqTPLjhyZ8",
        "outputId": "c9af7176-b22c-4a6c-bf1a-f729637dbf19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score with smoothing: 0.0968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygL9oPdSikXV",
        "outputId": "e0191e2f-046c-44ce-86f1-ca970e0ba75c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge) (1.17.0)\n",
            "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge  # Import the ROUGE scoring class from the rouge package\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "rouge = Rouge()  # Create a ROUGE object to compute ROUGE-1, ROUGE-2, and ROUGE-L scores\n",
        "\n",
        "# Compute ROUGE scores\n",
        "scores = rouge.get_scores([' '.join(candidates[0])], [' '.join(references[0])])\n",
        "# .get_scores(): computes ROUGE scores between candidate and reference texts\n",
        "# Parameters:\n",
        "#   candidates[0] – predicted sentence joined as a string: e.g., ['hi', 'how', 'you'] -> \"hi how you\"\n",
        "#   references[0] – reference sentence joined as a string: e.g., ['hello', 'how', 'are', 'you'] -> \"hello how are you\"\n",
        "# Returns:\n",
        "#   A list of dictionaries containing ROUGE-1, ROUGE-2, and ROUGE-L precision, recall, and F1-score\n",
        "\n",
        "print(f\"ROUGE score: {scores[0]}\")  # Print the ROUGE scores for the first (and only) candidate-reference pair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5eXs4NTh0lk",
        "outputId": "0c79a591-a62a-47db-dfe7-a4ba72f1284c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE score: {'rouge-1': {'r': 0.5, 'p': 0.6666666666666666, 'f': 0.5714285665306124}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.5, 'p': 0.6666666666666666, 'f': 0.5714285665306124}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk  # Import the Natural Language Toolkit library (used for NLP tasks)\n",
        "nltk.download('wordnet')  # Download the WordNet lexical database (required for METEOR score synonym matching)\n",
        "\n",
        "from nltk.translate import meteor_score  # Import the METEOR scoring function from NLTK\n",
        "\n",
        "# Example: reference and candidate sentences (tokenized)\n",
        "references = [[\"hello\", \"how\", \"are\", \"you\"]]  # Reference sentence (ground truth), tokenized as a list of words\n",
        "candidates = [[\"hi\", \"how\", \"you\"]]  # Candidate sentence (model prediction), also tokenized\n",
        "\n",
        "# Compute METEOR score\n",
        "meteor = meteor_score.single_meteor_score(references[0], candidates[0])\n",
        "# Parameters:\n",
        "#   references[0] – a list of tokens from the reference sentence\n",
        "#   candidates[0] – a list of tokens from the predicted sentence\n",
        "# The function computes a METEOR score considering exact, stem, synonym, and paraphrase matches\n",
        "\n",
        "print(f\"METEOR score: {meteor:.4f}\")  # Print the computed METEOR score, rounded to 4 decimal places"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9jnmA4fh6Xj",
        "outputId": "72266605-156d-40b2-8b02-ae373c6d0c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "METEOR score: 0.6553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example scores for Accuracy, BLEU, and METEOR\n",
        "accuracy = 0.5790\n",
        "bleu = 0.0968\n",
        "meteor = 0.6553\n",
        "\n",
        "# Create a list of the metrics and their values\n",
        "metrics = ['Accuracy', 'BLEU', 'METEOR']\n",
        "scores = [accuracy, bleu, meteor]\n",
        "\n",
        "# Plotting the comparison graph\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(metrics, scores, color=['brown', 'red', 'violet'])\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Comparison of Model Evaluation Metrics')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "2MP3YV5niAqI",
        "outputId": "65561993-d0fe-4ab1-918b-0a11142027be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time  # Import the time module to measure execution time\n",
        "import numpy as np  # Import numpy for numerical operations (though not used directly here)\n",
        "\n",
        "# Assume X_test is your test dataset and model is already trained\n",
        "# If the dataset is large, you can test only a small subset\n",
        "\n",
        "num_samples = 100  # Number of test samples to evaluate inference time on\n",
        "X_sample = X_test[:num_samples]  # Take the first 100 samples from test data\n",
        "\n",
        "# Warm up the model (optional but helps avoid cold-start delays for timing accuracy)\n",
        "_ = model.predict(X_sample[:1])\n",
        "# Runs a single prediction to initialize any lazy-loading operations in the model\n",
        "\n",
        "# Start timing\n",
        "start_time = time.time()  # Record the current time before prediction starts\n",
        "\n",
        "# Run inference on the selected samples\n",
        "_ = model.predict(X_sample, batch_size=1, verbose=0)\n",
        "# Predict outputs for X_sample\n",
        "# Parameters:\n",
        "#   batch_size=1 – Predict one sample at a time for accurate per-sample timing\n",
        "#   verbose=0 – Suppress output during prediction\n",
        "\n",
        "# End timing\n",
        "end_time = time.time()  # Record the current time after prediction ends\n",
        "\n",
        "# Calculate the total and average inference time\n",
        "total_time = end_time - start_time  # Total time taken for inference on num_samples\n",
        "avg_inference_time = total_time / num_samples  # Average time per individual sample\n",
        "\n",
        "# Print total and average inference time\n",
        "print(f\"Inference time for {num_samples} samples: {total_time:.4f} seconds\")\n",
        "# .4f formats the number to 4 decimal places\n",
        "\n",
        "print(f\"Average inference time per sample: {avg_inference_time:.6f} seconds\")\n",
        "# .6f formats the number to 6 decimal places for more precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmgWtEXpjP7u",
        "outputId": "b00be5d5-3d64-4513-c96d-49d3b0e43754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step\n",
            "Inference time for 100 samples: 0.2494 seconds\n",
            "Average inference time per sample: 0.002494 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Analyze and Compare**"
      ],
      "metadata": {
        "id": "izW5qPTulnVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Header and cell data\n",
        "header = [\n",
        "    \"Criteria\",\n",
        "    \"LSTM/GRU<br>(No Attention)\",\n",
        "    \"Attention (Bahdanau/Luong)\",\n",
        "    \"Transformer (Self-Attention)\"\n",
        "]\n",
        "\n",
        "cells = [\n",
        "    [\"Accuracy / BLEU\", \"0.3976\", \"1\", \"0.0968\"],\n",
        "    [\"ROUGE / METEOR\", \"0.8333\", \"0.9921875\", \"0.6553\"],\n",
        "    [\"Training Time\", \"43.9 seconds\", \"78.7 seconds\", \"48.34 seconds\"],\n",
        "    [\"Inference Speed\", \"5.1971 seconds\", \"0.015274 seconds/sample\", \"0.015274 seconds/sample\"],\n",
        "    [\"Model Complexity\", \"2,632,627\", \"1,172,805\", \"1,172,805\"],\n",
        "    [\"Interpretability\", \"✔ (Attention Maps)\", \"✔ (Attention Maps)\", \"✔ (Attention Heads)\"]\n",
        "]\n",
        "\n",
        "# Add <br><br> to simulate vertical spacing\n",
        "for row in cells:\n",
        "    for i in range(len(row)):\n",
        "        row[i] = f\"{row[i]}<br><br>\"\n",
        "\n",
        "# Transpose\n",
        "transposed_cells = list(map(list, zip(*cells)))\n",
        "\n",
        "# Create table with spacing\n",
        "fig = go.Figure(data=[go.Table(\n",
        "    header=dict(values=header, fill_color='paleturquoise', align='left', font=dict(size=14)),\n",
        "    cells=dict(values=transposed_cells, fill_color='lavender', align='left', font=dict(size=13), height=40)\n",
        ")])\n",
        "\n",
        "fig.update_layout(title='Comparison Table: Attention Mechanisms')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "LR00LlHSlEtr",
        "outputId": "aa98b3a4-140f-48bb-bdcf-9435f481b92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"bfa00529-6044-4de2-b68b-0abbc48deec3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bfa00529-6044-4de2-b68b-0abbc48deec3\")) {                    Plotly.newPlot(                        \"bfa00529-6044-4de2-b68b-0abbc48deec3\",                        [{\"cells\":{\"align\":\"left\",\"fill\":{\"color\":\"lavender\"},\"font\":{\"size\":13},\"height\":40,\"values\":[[\"Accuracy \\u002f BLEU\\u003cbr\\u003e\\u003cbr\\u003e\",\"ROUGE \\u002f METEOR\\u003cbr\\u003e\\u003cbr\\u003e\",\"Training Time\\u003cbr\\u003e\\u003cbr\\u003e\",\"Inference Speed\\u003cbr\\u003e\\u003cbr\\u003e\",\"Model Complexity\\u003cbr\\u003e\\u003cbr\\u003e\",\"Interpretability\\u003cbr\\u003e\\u003cbr\\u003e\"],[\"0.3976\\u003cbr\\u003e\\u003cbr\\u003e\",\"0.8333\\u003cbr\\u003e\\u003cbr\\u003e\",\"43.9 seconds\\u003cbr\\u003e\\u003cbr\\u003e\",\"5.1971 seconds\\u003cbr\\u003e\\u003cbr\\u003e\",\"2,632,627\\u003cbr\\u003e\\u003cbr\\u003e\",\"✔ (Attention Maps)\\u003cbr\\u003e\\u003cbr\\u003e\"],[\"1\\u003cbr\\u003e\\u003cbr\\u003e\",\"0.9921875\\u003cbr\\u003e\\u003cbr\\u003e\",\"78.7 seconds\\u003cbr\\u003e\\u003cbr\\u003e\",\"0.015274 seconds\\u002fsample\\u003cbr\\u003e\\u003cbr\\u003e\",\"1,172,805\\u003cbr\\u003e\\u003cbr\\u003e\",\"✔ (Attention Maps)\\u003cbr\\u003e\\u003cbr\\u003e\"],[\"0.0968\\u003cbr\\u003e\\u003cbr\\u003e\",\"0.6553\\u003cbr\\u003e\\u003cbr\\u003e\",\"48.34 seconds\\u003cbr\\u003e\\u003cbr\\u003e\",\"0.015274 seconds\\u002fsample\\u003cbr\\u003e\\u003cbr\\u003e\",\"1,172,805\\u003cbr\\u003e\\u003cbr\\u003e\",\"✔ (Attention Heads)\\u003cbr\\u003e\\u003cbr\\u003e\"]]},\"header\":{\"align\":\"left\",\"fill\":{\"color\":\"paleturquoise\"},\"font\":{\"size\":14},\"values\":[\"Criteria\",\"LSTM\\u002fGRU\\u003cbr\\u003e(No Attention)\",\"Attention (Bahdanau\\u002fLuong)\",\"Transformer (Self-Attention)\"]},\"type\":\"table\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Comparison Table: Attention Mechanisms\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bfa00529-6044-4de2-b68b-0abbc48deec3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}